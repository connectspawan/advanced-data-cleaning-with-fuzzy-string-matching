{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8dbc753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n",
      "\n",
      "Exact duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load the dataset\n",
    "data = \"data/tested.csv\"\n",
    "df = pd.read_csv(data) \n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for duplicates based on exact matches\n",
    "print(\"\\nExact duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f09417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after cleaning:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           1\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkuma\\AppData\\Local\\Temp\\ipykernel_11064\\291772805.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)  # Impute Age with median\n",
      "C:\\Users\\pkuma\\AppData\\Local\\Temp\\ipykernel_11064\\291772805.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Impute Embarked with mode\n",
      "C:\\Users\\pkuma\\AppData\\Local\\Temp\\ipykernel_11064\\291772805.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Cabin'].fillna('Unknown', inplace=True)  # Impute Cabin with placeholder\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)  # Impute Age with median\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Impute Embarked with mode\n",
    "df['Cabin'].fillna('Unknown', inplace=True)  # Impute Cabin with placeholder\n",
    "\n",
    "# Standardize 'Name' column\n",
    "df['Name'] = df['Name'].str.strip().str.lower()  # Remove extra spaces and convert to lowercase\n",
    "\n",
    "# Check for missing values after cleaning\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c729ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential duplicates (index, name1, name2, similarity score):\n"
     ]
    }
   ],
   "source": [
    "# Function to find similar names\n",
    "def find_duplicates(names, threshold=90):\n",
    "    duplicates = []\n",
    "    for i, name in enumerate(names):\n",
    "        # Compare with all other names\n",
    "        matches = process.extract(name, names[i+1:], scorer=fuzz.token_sort_ratio)\n",
    "        # Filter matches above threshold\n",
    "        for match, score in matches:\n",
    "            if score >= threshold:\n",
    "                # Find the index of the match in names[i+1:]\n",
    "                index = names[i+1:].index(match)\n",
    "                duplicates.append((i, index + i + 1, name, match, score))\n",
    "    return duplicates\n",
    "\n",
    "# Apply fuzzy matching to 'Name' column\n",
    "names = df['Name'].tolist()\n",
    "duplicates = find_duplicates(names, threshold=90)\n",
    "\n",
    "# Display potential duplicates\n",
    "print(\"\\nPotential duplicates (index, name1, name2, similarity score):\")\n",
    "for dup in duplicates:\n",
    "    idx1, idx2, name1, name2, score = dup\n",
    "    print(f\"Index {idx1} vs {idx2}: {name1} | {name2} | Score: {score}\")\n",
    "\n",
    "# Example: Inspect duplicate rows\n",
    "if duplicates:\n",
    "    duplicate_indices = set([dup[0] for dup in duplicates] + [dup[1] for dup in duplicates])\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df.iloc[list(duplicate_indices)][['PassengerId', 'Name', 'Age', 'Ticket', 'Pclass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65972137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No duplicates found.\n",
      "\n",
      "Cleaned dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          418 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        418 non-null    object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates based on fuzzy matches\n",
    "if duplicates:\n",
    "    indices_to_drop = [dup[1] for dup in duplicates]  # Keep first occurrence\n",
    "    df_cleaned = df.drop(indices_to_drop).reset_index(drop=True)\n",
    "    print(f\"\\nRemoved {len(indices_to_drop)} duplicate rows.\")\n",
    "else:\n",
    "    df_cleaned = df.copy()\n",
    "    print(\"\\nNo duplicates found.\")\n",
    "\n",
    "# Verify the cleaned dataset\n",
    "print(\"\\nCleaned dataset info:\")\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737ffd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact duplicates in cleaned dataset: 0\n",
      "\n",
      "Cleaned dataset saved as 'data/cleaned_tested.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Validate: Check for remaining duplicates\n",
    "print(\"\\nExact duplicates in cleaned dataset:\", df_cleaned.duplicated().sum())\n",
    "\n",
    "# Export cleaned dataset\n",
    "df_cleaned.to_csv('data/cleaned_tested.csv', index=False)\n",
    "print(\"\\nCleaned dataset saved as 'data/cleaned_tested.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03006cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
