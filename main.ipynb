{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8dbc753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n",
      "\n",
      "Exact duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load the dataset\n",
    "data = \"data/tested.csv\"\n",
    "df = pd.read_csv(data) \n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for duplicates based on exact matches\n",
    "print(\"\\nExact duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f09417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after cleaning:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           1\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())  # Impute Age with median\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])  # Impute Embarked with mode\n",
    "df['Cabin'] = df['Cabin'].fillna('Unknown')  # Impute Cabin with placeholder\n",
    "\n",
    "# Standardize 'Name' column\n",
    "df['Name'] = df['Name'].str.strip().str.lower()  # Remove extra spaces and convert to lowercase\n",
    "\n",
    "# Check for missing values after cleaning\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c729ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Potential duplicates (index, name1, name2, similarity score):\n"
     ]
    }
   ],
   "source": [
    "# Function to find similar names\n",
    "def find_duplicates(names, threshold=90):\n",
    "    duplicates = []\n",
    "    for i, name in enumerate(names):\n",
    "        # Compare with all other names\n",
    "        matches = process.extract(name, names[i+1:], scorer=fuzz.token_sort_ratio)\n",
    "        # Filter matches above threshold\n",
    "        for match, score in matches:\n",
    "            if score >= threshold:\n",
    "                # Find the index of the match in names[i+1:]\n",
    "                index = names[i+1:].index(match)\n",
    "                duplicates.append((i, index + i + 1, name, match, score))\n",
    "    return duplicates\n",
    "\n",
    "# Apply fuzzy matching to 'Name' column\n",
    "names = df['Name'].tolist()\n",
    "duplicates = find_duplicates(names, threshold=90)\n",
    "\n",
    "# Display potential duplicates\n",
    "print(\"\\nPotential duplicates (index, name1, name2, similarity score):\")\n",
    "for dup in duplicates:\n",
    "    idx1, idx2, name1, name2, score = dup\n",
    "    print(f\"Index {idx1} vs {idx2}: {name1} | {name2} | Score: {score}\")\n",
    "\n",
    "# Example: Inspect duplicate rows\n",
    "if duplicates:\n",
    "    duplicate_indices = set([dup[0] for dup in duplicates] + [dup[1] for dup in duplicates])\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df.iloc[list(duplicate_indices)][['PassengerId', 'Name', 'Age', 'Ticket', 'Pclass']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65972137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No duplicates found.\n",
      "\n",
      "Cleaned dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          418 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        418 non-null    object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates based on fuzzy matches\n",
    "if duplicates:\n",
    "    indices_to_drop = [dup[1] for dup in duplicates]  # Keep first occurrence\n",
    "    df_cleaned = df.drop(indices_to_drop).reset_index(drop=True)\n",
    "    print(f\"\\nRemoved {len(indices_to_drop)} duplicate rows.\")\n",
    "else:\n",
    "    df_cleaned = df.copy()\n",
    "    print(\"\\nNo duplicates found.\")\n",
    "\n",
    "# Verify the cleaned dataset\n",
    "print(\"\\nCleaned dataset info:\")\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737ffd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact duplicates in cleaned dataset: 0\n",
      "\n",
      "Cleaned dataset saved as 'data/cleaned_tested.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Validate: Check for remaining duplicates\n",
    "print(\"\\nExact duplicates in cleaned dataset:\", df_cleaned.duplicated().sum())\n",
    "\n",
    "# Export cleaned dataset\n",
    "df_cleaned.to_csv('data/cleaned_tested.csv', index=False)\n",
    "print(\"\\nCleaned dataset saved as 'data/cleaned_tested.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03006cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
